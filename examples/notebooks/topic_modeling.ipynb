{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2960a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%env CONSOLE_WIDTH=140\n",
    "\n",
    "from kiara.interfaces.python_api.workflow import Workflow\n",
    "from kiara.utils.jupyter import graph_to_image\n",
    "from kiara.utils.cli import terminal_print_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f0118",
   "metadata": {},
   "source": [
    "# Creating the workflow object <a class=\"anchor\" id=\"create_workflow_obj\"></a>\n",
    "\n",
    "As the first step we create a [`Workflow`](https://dharpa.org/kiara/latest/reference/kiara/interfaces/python_api/workflow/) object, which is a convenience class that manages workflow state, internal consistency and history for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"Example topic-modeling end-to-end workflow.\"\"\"\n",
    "workflow = Workflow.create(\"topic_modeling\", doc=doc, replace_existing_alias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90f461c",
   "metadata": {},
   "source": [
    "# Assembling the workflow <a class=\"anchor\" id=\"assembly\"></a>\n",
    "\n",
    "The first step in the creation of our workflow is to create the individual steps from the available *kiara* modules.\n",
    "\n",
    "A list of available modules and their aliases can be found here: TODO\n",
    "\n",
    "## Creating the steps of the workflow <a class=\"anchor\" id=\"creating_steps\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8908d27",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Creating step: import_text_corpus\n",
    "workflow.add_step(operation=\"import.file_bundle\", step_id=\"import_text_corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45c7d3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Creating step: create_stopwords_list\n",
    "workflow.add_step(operation=\"create.stopwords_list\", step_id=\"create_stopwords_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160bb420",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Creating step: create_text_corpus\n",
    "step_create_text_corpus_config = {'constants': {}, 'defaults': {}, 'source_type': 'text_file_bundle', 'target_type': 'table', 'ignore_errors': False}\n",
    "workflow.add_step(\n",
    "    operation=\"create.table\",\n",
    "    module_config=step_create_text_corpus_config,\n",
    "    step_id=\"create_text_corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75968d1e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Connecting input(s) of step 'create_text_corpus'\n",
    "workflow.connect_fields(\"create_text_corpus.text_file_bundle\", \"import_text_corpus.file_bundle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7e63b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Creating step: extract_texts_column\n",
    "workflow.add_step(operation=\"table.cut_column\", step_id=\"extract_texts_column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5e8a6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Connecting input(s) of step 'extract_texts_column'\n",
    "workflow.connect_fields(\"extract_texts_column.table\", \"create_text_corpus.table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da3322",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Creating step: extract_filename_column\n",
    "workflow.add_step(operation=\"table.cut_column\", step_id=\"extract_filename_column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc9e96c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Connecting input(s) of step 'extract_filename_column'\n",
    "workflow.connect_fields(\"extract_filename_column.table\", \"create_text_corpus.table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6943a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Creating step: create_date_array\n",
    "workflow.add_step(operation=\"parse.date_array\", step_id=\"create_date_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e52cbad",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Connecting input(s) of step 'create_date_array'\n",
    "workflow.connect_fields(\"create_date_array.array\", \"extract_filename_column.array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9ef7b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Creating step: tokenize_content\n",
    "workflow.add_step(operation=\"tokenize.texts_array\", step_id=\"tokenize_content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae235a2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Connecting input(s) of step 'tokenize_content'\n",
    "workflow.connect_fields(\"tokenize_content.texts_array\", \"extract_texts_column.array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea46850",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Creating step: preprocess_corpus\n",
    "workflow.add_step(operation=\"preprocess.tokens_array\", step_id=\"preprocess_corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec15f48",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Connecting input(s) of step 'preprocess_corpus'\n",
    "workflow.connect_fields(\"preprocess_corpus.tokens_array\", \"tokenize_content.tokens_array\")\n",
    "workflow.connect_fields(\"preprocess_corpus.remove_stopwords\", \"create_stopwords_list.stopwords_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f177d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Creating step: generate_lda\n",
    "workflow.add_step(operation=\"generate.LDA.for.tokens_array\", step_id=\"generate_lda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eadbea2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Connecting input(s) of step 'generate_lda'\n",
    "workflow.connect_fields(\"generate_lda.tokens_array\", \"preprocess_corpus.tokens_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd04c78",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Setting workflow input/output names (optional)\n",
    "\n",
    "To make our workflow nicer to use, we can set aliases for its inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78d20d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "workflow.set_input_alias(input_field=\"extract_texts_column.column_name\", alias=\"content_column_name\")\n",
    "workflow.set_input_alias(input_field=\"extract_filename_column.column_name\", alias=\"filename_column_name\")\n",
    "workflow.set_input_alias(input_field=\"import_text_corpus.path\", alias=\"text_corpus_folder_path\")\n",
    "workflow.set_input_alias(input_field=\"create_date_array.min_index\", alias=\"date_parse_min\")\n",
    "workflow.set_input_alias(input_field=\"create_date_array.max_index\", alias=\"date_parse_max\")\n",
    "workflow.set_input_alias(input_field=\"create_date_array.force_non_null\", alias=\"date_force_non_null\")\n",
    "workflow.set_input_alias(input_field=\"create_date_array.remove_tokens\", alias=\"date_remove_tokensl\")\n",
    "workflow.set_input_alias(input_field=\"tokenize_content.tokenize_by_word\", alias=\"tokenize_by_word\")\n",
    "workflow.set_input_alias(input_field=\"generate_lda.num_topics_min\", alias=\"num_topics_min\")\n",
    "workflow.set_input_alias(input_field=\"generate_lda.num_topics_max\", alias=\"num_topics_max\")\n",
    "workflow.set_input_alias(input_field=\"generate_lda.compute_coherence\", alias=\"compute_coherence\")\n",
    "workflow.set_input_alias(input_field=\"generate_lda.words_per_topic\", alias=\"words_per_topic\")\n",
    "workflow.set_input_alias(input_field=\"create_stopwords_list.languages\", alias=\"languages\")\n",
    "workflow.set_input_alias(input_field=\"create_stopwords_list.stopword_lists\", alias=\"stopword_lists\")\n",
    "workflow.set_input_alias(input_field=\"preprocess_corpus.to_lowercase\", alias=\"to_lowercase\")\n",
    "workflow.set_input_alias(input_field=\"preprocess_corpus.remove_alphanumeric\", alias=\"remove_alphanumeric\")\n",
    "workflow.set_input_alias(input_field=\"preprocess_corpus.remove_non_alpha\", alias=\"remove_non_alpha\")\n",
    "workflow.set_input_alias(input_field=\"preprocess_corpus.remove_all_numeric\", alias=\"remove_all_numeric\")\n",
    "workflow.set_input_alias(input_field=\"preprocess_corpus.remove_short_tokens\", alias=\"remove_short_tokens\")\n",
    "workflow.set_input_alias(input_field=\"preprocess_corpus.remove_stopwords\", alias=\"remove_stopwords\")\n",
    "\n",
    "\n",
    "workflow.set_output_alias(output_field=\"import_text_corpus.file_bundle\", alias=\"text_corpus_file_bundle\")\n",
    "workflow.set_output_alias(output_field=\"create_text_corpus.table\", alias=\"text_corpus_table\")\n",
    "workflow.set_output_alias(output_field=\"extract_texts_column.array\", alias=\"content_array\")\n",
    "workflow.set_output_alias(output_field=\"tokenize_content.tokens_array\", alias=\"tokenized_corpus\")\n",
    "workflow.set_output_alias(output_field=\"preprocess_corpus.tokens_array\", alias=\"preprocessed_corpus\")\n",
    "workflow.set_output_alias(output_field=\"generate_lda.topic_models\", alias=\"topic_models\")\n",
    "workflow.set_output_alias(output_field=\"generate_lda.coherence_map\", alias=\"coherence_map\")\n",
    "workflow.set_output_alias(output_field=\"generate_lda.coherence_table\", alias=\"coherence_table\")\n",
    "workflow.set_output_alias(output_field=\"create_date_array.date_array\", alias=\"date_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96da7a77",
   "metadata": {},
   "source": [
    "# Workflow information <a class=\"anchor\" id=\"pipeline_info\"></a>\n",
    "\n",
    "After our workflow is wired up, we look can look at its structure, and other properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a425ea1",
   "metadata": {},
   "source": [
    "\n",
    "## Workflow status\n",
    "\n",
    "A workflow consists of a series of 'states', the most relevant is always the most recent one. We can investigate\n",
    "that latest states details like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16308eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0ba708",
   "metadata": {},
   "source": [
    "## Pipeline execution graph\n",
    "\n",
    "Let's look at the current execution graph for the current workflow pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49286ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_to_image(workflow.pipeline.execution_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f767a287",
   "metadata": {},
   "source": [
    "# Workflow inputs <a class=\"anchor\" id=\"pipeline_inputs\"></a>\n",
    "\n",
    "Once a workflow has an assembled pipeline, we can set it's inputs. We use the input field\n",
    "names that we got from the result of the `workflow.current_state` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5dce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.set_input(\"text_corpus_folder_path\", \"/home/markus/projects/kiara/dev/kiara.examples/examples/pipelines/topic_modeling/../../data/text_corpus/data\")\n",
    "workflow.set_input(\"content_column_name\", \"content\")\n",
    "workflow.set_input(\"filename_column_name\", \"file_name\")\n",
    "workflow.set_input(\"date_force_non_null\", None)\n",
    "workflow.set_input(\"date_parse_min\", 11)\n",
    "workflow.set_input(\"date_parse_max\", 21)\n",
    "workflow.set_input(\"date_remove_tokensl\", None)\n",
    "workflow.set_input(\"tokenize_by_word\", None)\n",
    "workflow.set_input(\"languages\", ['italian'])\n",
    "workflow.set_input(\"stopword_lists\", [])\n",
    "workflow.set_input(\"to_lowercase\", None)\n",
    "workflow.set_input(\"remove_alphanumeric\", None)\n",
    "workflow.set_input(\"remove_non_alpha\", None)\n",
    "workflow.set_input(\"remove_all_numeric\", None)\n",
    "workflow.set_input(\"remove_short_tokens\", None)\n",
    "workflow.set_input(\"num_topics_min\", 7)\n",
    "workflow.set_input(\"num_topics_max\", 9)\n",
    "workflow.set_input(\"compute_coherence\", True)\n",
    "workflow.set_input(\"words_per_topic\", None)\n",
    "\n",
    "\n",
    "# process all workflow steps that can be processed\n",
    "workflow.process_steps()\n",
    "\n",
    "# print the current state, after we set our inputs\n",
    "workflow.current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565bf79",
   "metadata": {},
   "source": [
    "# Workflow outputs <a class=\"anchor\" id=\"pipeline_outputs\"></a>\n",
    "\n",
    "To print the actual data of the workflows' current outputs, we call the `current_output_values` property of the workflow object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208debe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.current_output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab8d18e",
   "metadata": {},
   "source": [
    "# Workflow snapshot <a class=\"anchor\" id=\"snapshot\"></a>\n",
    "\n",
    "So far, our workflow only exists in memory. If we want to save it so we can have a look at it again at a later stage, we can snapshot the current state, which will save the current structure of the internal pipeline, as well as all inputs that are currently used. In addition, this will register the workflow under the alias we specified on top of this file when creating the `Workflow` object (in our case: `topic_modeling`).\n",
    "\n",
    "If we would not not specify `save=True`, the structure of the pipeline and inputs would still be frozen and kept, but only in memory, and we'd only be able to access it in our current session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db336c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.snapshot(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116d5f9",
   "metadata": {},
   "source": [
    "Now, we can access our workflow in other environments, for example from the commandline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c073c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kiara workflow list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7430ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kiara workflow explain topic_modeling"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "region,endregion",
   "formats": "ipynb,.pct.py:percent,.lgt.py:light,.spx.py:sphinx,md,Rmd,.pandoc.md:pandoc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
